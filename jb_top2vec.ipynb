{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Record Id', 'Record URL', 'Document URL', 'Title', 'Original title',\n",
      "       'Date of original text', 'Last amended date', 'Available website',\n",
      "       'Language of document', 'Country/Territory', 'Regional organizations',\n",
      "       'Territorial subdivision', 'Type of text', 'Repealed', 'Abstract',\n",
      "       'Primary subjects', 'Domain', 'Keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"FAOLEX_ALL.csv\")\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "keywords=list(data[\"Keywords\"])\n",
    "country=list(data[\"Country/Territory\"])\n",
    "i=0\n",
    "# Split alle keywords op i en liste og ændrer nan til at være en str med Nan\n",
    "for words in keywords:\n",
    "    if type(words)!=str:\n",
    "        #print(\"type= \",type(words),\" Index = \", i)\n",
    "        words=\"Nan\"\n",
    "    if type(country[i])!=str:\n",
    "        country[i]=\"NaN\"\n",
    "    keywords[i]=words.split(\";\")\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maritime zone', ' territorial sea', ' sovereignty']\n"
     ]
    }
   ],
   "source": [
    "# prints keywords for a single text\n",
    "print(keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_words=[]\n",
    "\n",
    "# Stem keywords\n",
    "for i in range(len(keywords)):\n",
    "    stemmed_words.append([stemmer.stem(word) for word in keywords[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marine fisheries', ' molluscs', ' fishing authorization', ' non-governmental entity', ' fishery management and conservation']\n",
      "['marine fisheri', ' mollusc', ' fishing author', ' non-governmental ent', ' fishery management and conserv']\n"
     ]
    }
   ],
   "source": [
    "print(keywords[14083])\n",
    "print(stemmed_words[14083])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54324\n"
     ]
    }
   ],
   "source": [
    "# Count number documents in a language\n",
    "languages=list(data[\"Language of document\"])\n",
    "print(languages.count(\"English\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 16:11:01,652 - top2vec - INFO - Pre-processing documents for training\n",
      "2023-05-29 16:11:09,871 - top2vec - INFO - Creating joint document/word embedding\n",
      "2023-05-29 16:15:44,359 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2023-05-29 16:17:30,608 - top2vec - INFO - Finding dense areas of documents\n",
      "2023-05-29 16:17:38,471 - top2vec - INFO - Finding topics\n"
     ]
    }
   ],
   "source": [
    "# Make a top2vec topic model\n",
    "from top2vec import Top2Vec\n",
    "i=0\n",
    "for word in keywords:\n",
    "    keywords[i]=\"\".join(word)\n",
    "    i+=1\n",
    "model = Top2Vec(keywords,embedding_model=\"doc2vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1410, 1365, 1300, ...,   22,   21,   20], dtype=int64)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words,word_scores,topic_nums = model.get_topics(10)\n",
    "\n",
    "# Topic words: Ord i en given topic\n",
    "#Words_score: Hvor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['continental' 'territorial' 'shelf' 'maritime' 'eez' 'sea' 'exclusive'\n",
      "  'economic' 'zone' 'seas' 'high' 'deep' 'sovereignty' 'transshipment'\n",
      "  'fishing' 'catch' 'port' 'navigation' 'bycatch' 'fisheries' 'coastal'\n",
      "  'mesh' 'allowable' 'diadromous' 'vessel' 'total' 'foreign' 'marine'\n",
      "  'bed' 'method' 'cartilaginous' 'harbour' 'fishery' 'landing' 'charge'\n",
      "  'migratory' 'mammals' 'exploration' 'fishes' 'state' 'iuu' 'size'\n",
      "  'illegal' 'stock' 'unreported' 'unregulated' 'seasons' 'commercial'\n",
      "  'turtles' 'gear']\n",
      " ['mesh' 'fishing' 'fishes' 'seasons' 'method' 'fisheries' 'allowable'\n",
      "  'bycatch' 'catch' 'size' 'cartilaginous' 'total' 'charge' 'vessel'\n",
      "  'port' 'fishery' 'landing' 'crustaceans' 'gear' 'diadromous'\n",
      "  'commercial' 'quota' 'transshipment' 'artisanal' 'prohibited' 'turtles'\n",
      "  'foreign' 'allocation' 'molluscs' 'seas' 'high' 'migratory' 'marine'\n",
      "  'mammals' 'stock' 'territorial' 'exclusive' 'unregulated' 'unreported'\n",
      "  'iuu' 'illegal' 'eez' 'state' 'repopulation' 'sea' 'enhancement'\n",
      "  'mariculture' 'coral' 'area' 'shelf']\n",
      " ['logging' 'timber' 'forest' 'extraction' 'clearing' 'service'\n",
      "  'fuelwood' 'wood' 'forestry' 'fires' 'afforestation' 'inventory'\n",
      "  'reforestation' 'concession' 'agro' 'recreational' 'private' 'parks'\n",
      "  'services' 'payments' 'for' 'wildlife' 'payment' 'planting' 'pes'\n",
      "  'conservation' 'lease' 'contracts' 'measures' 'medicinal' 'collecting'\n",
      "  'grazing' 'mountain' 'capture' 'hunting' 'prescription' 'harvesting'\n",
      "  'framework' 'adverse' 'material' 'common' 'erosion' 'royalties'\n",
      "  'vested' 'community' 'species' 'improvement' 'seeds' 'tenure' 'survey']\n",
      " ['seeds' 'floriculture' 'planting' 'material' 'variety' 'breeders'\n",
      "  'fibre' 'plant' 'oleaginous' 'vegetables' 'weeds' 'legumes' 'timber'\n",
      "  'edible' 'certification' 'oenological' 'rice' 'fruits' 'cane'\n",
      "  'viticulture' 'nuts' 'grains' 'beet' 'tobacco' 'quarantine' 'wood'\n",
      "  'logging' 'crops' 'cereals' 'intellectual' 'tea' 'extraction' 'pests'\n",
      "  'production' 'forest' 'steroids' 'genetic' 'coffee' 'cocoa' 'clearing'\n",
      "  'biological' 'sugar' 'harvest' 'biotechnology' 'forestry' 'labelling'\n",
      "  'packaging' 'diseases' 'service' 'post']\n",
      " ['viticulture' 'oenological' 'beverages' 'practices' 'vending' 'tobacco'\n",
      "  'fruits' 'additives' 'nuts' 'treated' 'edible' 'labelling'\n",
      "  'floriculture' 'packaging' 'legumes' 'indication' 'grains' 'based'\n",
      "  'safety' 'geographical' 'fraud' 'deceit' 'adulteration' 'vegetables'\n",
      "  'cane' 'condiments' 'certification' 'meat' 'rice' 'handling' 'beet'\n",
      "  'processing' 'maximum' 'internal' 'haccp' 'codex' 'spices'\n",
      "  'alimentarius' 'sugar' 'coffee' 'seeds' 'residue' 'procedures'\n",
      "  'mineral' 'oilseeds' 'limit' 'tea' 'traceability' 'consumer' 'good']\n",
      " ['allowable' 'fishing' 'catch' 'total' 'mesh' 'bycatch' 'seasons'\n",
      "  'fishes' 'fisheries' 'method' 'cartilaginous' 'landing' 'vessel' 'size'\n",
      "  'diadromous' 'fishery' 'crustaceans' 'transshipment' 'quota' 'charge'\n",
      "  'seas' 'port' 'allocation' 'gear' 'commercial' 'artisanal' 'high'\n",
      "  'migratory' 'foreign' 'marine' 'molluscs' 'mammals' 'eez' 'prohibited'\n",
      "  'exclusive' 'stock' 'territorial' 'turtles' 'unregulated' 'iuu'\n",
      "  'illegal' 'unreported' 'methods' 'sea' 'enhancement' 'continental'\n",
      "  'state' 'repopulation' 'fee' 'mariculture']\n",
      " ['air' 'layer' 'noise' 'pollution' 'control' 'ozone' 'substances'\n",
      "  'emissions' 'hazardous' 'trading' 'effluent' 'discharge' 'audit'\n",
      "  'environmental' 'disposal' 'cleaning' 'domestic' 'movement'\n",
      "  'prevention' 'pays' 'sources' 'waste' 'polluter' 'oil' 'recycling'\n",
      "  'solid' 'reuse' 'freshwater' 'mechanism' 'outer' 'coal' 'radiation'\n",
      "  'sewerage' 'space' 'eia' 'standards' 'nuclear' 'charges' 'detergents'\n",
      "  'biofuel' 'energy' 'clean' 'effects' 'transboundary' 'industrial' 'gas'\n",
      "  'rehabilitation' 'renewable' 'quality' 'impact']\n",
      " ['domestic' 'sources' 'waste' 'solid' 'disposal' 'prevention' 'reuse'\n",
      "  'recycling' 'hazardous' 'movement' 'plastic' 'discharge' 'substances'\n",
      "  'control' 'pollution' 'pays' 'effluent' 'polluter' 'audit' 'economy'\n",
      "  'circular' 'sewerage' 'principle' 'noise' 'environmental'\n",
      "  'transboundary' 'bioenergy' 'air' 'charges' 'industrial' 'coal'\n",
      "  'cleaning' 'radiation' 'rehabilitation' 'detergents' 'oil' 'non' 'loss'\n",
      "  'eia' 'layer' 'environment' 'freshwater' 'water' 'groundwater'\n",
      "  'nuclear' 'emissions' 'organic' 'ecofriendly' 'integrated' 'standards']\n",
      " ['fishing' 'mesh' 'seasons' 'method' 'port' 'allowable' 'cartilaginous'\n",
      "  'charge' 'fishes' 'landing' 'bycatch' 'fisheries' 'total' 'catch'\n",
      "  'vessel' 'transshipment' 'diadromous' 'quota' 'prohibited' 'size'\n",
      "  'foreign' 'gear' 'commercial' 'fishery' 'crustaceans' 'allocation'\n",
      "  'high' 'unreported' 'seas' 'unregulated' 'artisanal' 'illegal' 'marine'\n",
      "  'mammals' 'migratory' 'iuu' 'stock' 'turtles' 'molluscs' 'state'\n",
      "  'mariculture' 'repopulation' 'enhancement' 'exclusive' 'territorial'\n",
      "  'coral' 'harbour' 'eez' 'area' 'inland']\n",
      " ['poisoning' 'steroids' 'hormones' 'toxicity' 'veterinary' 'limit'\n",
      "  'residue' 'maximum' 'mrl' 'residues' 'drugs' 'feed' 'feedstuffs'\n",
      "  'additives' 'procedures' 'haccp' 'slaughtering' 'sanitary' 'meat'\n",
      "  'treated' 'poultry' 'hygiene' 'safety' 'animal' 'vaccination' 'codex'\n",
      "  'labelling' 'antimicrobial' 'alimentarius' 'swine' 'disinfection'\n",
      "  'disinfestation' 'fraud' 'traceability' 'resistance' 'adulteration'\n",
      "  'fish' 'packaging' 'cattle' 'stock' 'amr' 'pesticides' 'dairy'\n",
      "  'diseases' 'welfare' 'quarantine' 'pests' 'deceit' 'inspection'\n",
      "  'intellectual']]\n"
     ]
    }
   ],
   "source": [
    "print(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 19012, Score: 0.9775562286376953\n",
      "-----------\n",
      "timber extraction/logging authorization/permit forest management/forest conservation\n",
      "-----------\n",
      "\n",
      "Document: 112243, Score: 0.974977970123291\n",
      "-----------\n",
      "forest management/forest conservation timber timber extraction/logging\n",
      "-----------\n",
      "\n",
      "Document: 30936, Score: 0.9747377038002014\n",
      "-----------\n",
      "forest management/forest conservation timber extraction/logging\n",
      "-----------\n",
      "\n",
      "Document: 57084, Score: 0.9746578931808472\n",
      "-----------\n",
      "forest management/forest conservation timber timber extraction/logging\n",
      "-----------\n",
      "\n",
      "Document: 1750, Score: 0.9742560386657715\n",
      "-----------\n",
      "timber extraction/logging protected area forest management/forest conservation\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=2, num_docs=5)\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\"-----------\")\n",
    "    print(doc)\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "topic_words,word_scores,topic_nums = model.get_topics()\n",
    "tal = max(topic_nums)\n",
    "#rækker = topic, colums = ord\n",
    "co_occurrence_matrix = np.zeros((tal,tal))\n",
    "for i in range(tal):\n",
    "    topic_words, w_score, topic_scores, t_nums = model.search_topics_by_vector(model.topic_vectors[i],tal)\n",
    "    for dist, topic_nb in zip(topic_scores, t_nums):\n",
    "        co_occurrence_matrix[i-1,topic_nb-1] = dist\n",
    "\n",
    "print(co_occurrence_matrix)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d6823c3c2b982c4c23d5cf67b2c8c8d3aa4d88d1118d558bbf6c63cb31594e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
